# XGBoost Classification Model - Airline Passenger Satisfaction Analysis

## ðŸ“Œ Project Overview

This project applies the XGBoost algorithm to classify airline passenger satisfaction using the `Invistico Airline` dataset. The implementation includes  data preprocessing, model training, hyperparameter tuning, and evaluation to identify key factors influencing passenger satisfaction.

## ðŸ“Š Dataset

**File:**Â `Invistico_Airline.csv`

- **Rows:**Â 129,880

- **Features:**Â 21 predictor variables + 1 target variable (`satisfaction`)

- **Target:**Â Binary classification (`satisfied`Â vsÂ `dissatisfied`)

### Key Features Include:

- Demographic information (Age, Customer Type, Class)

- Flight details (Flight Distance, Type of Travel, Departure/Arrival Delays)

- Service ratings (Seat comfort, Food and drink, Inflight services, Cleanliness, etc.)

## ðŸ—ï¸ Project Structure

### 1.Â **Data Preparation**

- Loaded and explored dataset structure

- Identified categorical variables requiring encoding

- Applied one-hot  encoding to:Â `satisfaction`,Â `Customer Type`,Â `Type of Travel`,Â `Class`

- Split data into training (75%) and testing (25%) sets

### 2. **Model Building**

- Implemented XGBoost Classifier with binary logistic objective

- Performed hyperparameter tuning using GridSearchCV with 5-fold cross-validation

### 3. **Hyperparameter Grid**

```
cv_params = {
    'max_depth': [4],
    'min_child_weight': [3, 5],
    'learning_rate': [0.1, 0.2],
    'n_estimators': [5, 10],
    'subsample': [0.7],
    'colsample_bytree': [0.7]
}
```

### 4.Â **Model Evaluation Metrics**

- Accuracy

- Precision

- Recall

- F1-Score (used as primary metric for refitting)

## ðŸ“ˆ Results

### Optimal Hyperparameters

```
{
    'colsample_bytree': 0.7,
    'learning_rate': 0.2,
    'max_depth': 4,
    'min_child_weight': 5,
    'n_estimators': 10,
    'subsample': 0.7
}
```

### Model Performance

- **Accuracy:**Â 89.58%

- **Precision:**Â 90.03%

- **Recall:**Â 91.15%

- **F1-Score:**Â 91.15%

### Confusion Matrix

The model demonstrates strong predictive power with:

- High true positive and true negative rates

- Low false positive and false negative rates

## ðŸ” Feature Importance

The project includes visualization of feature importance using XGBoost's built-in functionality, identifying which factors most significantly impact passenger satisfaction.

## ðŸŽ¯ Key Insights

1. **Model Performance:**Â The XGBoost model achieved excellent results with F1-score >91%, indicating strong predictive capability for passenger satisfaction.

2. **Business Implications:**Â The model can help airlines identify critical service areas needing improvement to enhance passenger satisfaction.

3. **Feature Analysis:**Â Service-related features appear to be significant predictors of satisfaction, though specific importance rankings are visualized in the notebook.